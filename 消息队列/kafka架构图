kafka 就是一般的MQ架构，通信协议基于tcp的二进制

kafka包括如下结构：
Producer
Topic
Broker【由分区组成Partition】
Consumer【消费组】
zk 管理配置，主体，分区，offset 等消息。
组成

发消息流程：
Producer 根据轮训负载发送消息到Partition

kafka 收到消息定时持久化到文件

Consumer 根据负载均衡策略去拉取消息并消费，同时上报offset。

【一般建议通过多副本机制来保证消息的可靠，而不是同步刷盘】



四、消息投递语义

kafka支持3种消息投递语义，
At most once：最多一次，消息可能会丢失，但不会重复
At least once：最少一次，消息不会丢失，可能会重复
Exactly once：只且一次，消息不丢失不重复，只且消费一次（0.11中实现，仅限于下游也是kafka）

At least once：（业务中使用比较多）

生产者】生产消息异常，消息是否成功写入不确定，重做，可能写入重复的消息
消费者】处理消息，业务处理成功后，更新offset失败，消费者重启的话，会重复消费
At most once：

先获取数据，再commit offset，最后进行业务处理。

生产者生产消息异常，不管，生产下一个消息，消息就丢了 acks = 0
消费者处理消息，先更新offset，再做业务处理，做业务处理失败，消费者重启，消息就丢了。

消费者如何处理At-most-once
At-most-once Kafka Consumer (Zero or More Deliveries)
   At-most-once consumer is the default behavior of a KAFKA consumer.

   To configure this type of consumer:

   Set ‘enable.auto.commit’ to true.

   Set ‘auto.commit.interval.ms’ to a lower timeframe.

   And do not make call to consumer.commitSync(); from the consumer. With this configuration of consumer, Kafka would auto commit offset at the specified interval.

Exactly once：

首先要保证消息不丢，再去保证不重复。所以盯着At least once的原因来搞。

生产者重做导致重复写入消息----生产保证幂等性
消费者重复消费---消灭重复消费，或者业务接口保证幂等性重复消费也没问题
业务处理的幂等性非常重要。Kafka控制不了，需要业务来实现。比如所判断消息是否已经处理。

解决重复消费有两个方法：

下游系统保证幂等性，重复消费也不会导致多条记录。
把commit offset和业务处理绑定成一个事务


五：生产的幂等性：

为每个producer分配一个pid，作为该producer的唯一标识。producer会为每一个<topic,partition>维护一个单调递增的seq。类似的，broker也会为每个<pid,topic,partition>记录下最新的seq。当req_seq == broker_seq+1时，broker才会接受该消息。因为：

消息的seq比broker的seq大超过时，说明中间有数据还没写入，即乱序了。
消息的seq不比broker的seq小，那么说明该消息已被保存。
开启：  Properties.put(“enable.idempotence”,true);


六：  事务性和原子性
     场景是这样的：

  先从多个源topic中获取数据。
  做业务处理，写到下游的多个目的topic。
  更新多个源topic的offset。
     其中第2、3点作为一个事务，要么全成功，要么全失败。这里得益与offset实际上是用特殊的topic去保存，这两点都归一为写多个topic的事务性处理。



kafka精华贴:https://www.cnblogs.com/tianqing/p/10808717.html